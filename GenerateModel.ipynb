{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c7ade5c",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center\"> Escuela Técnica Superior de Ingeniería Informática</p>\n",
    "<p style=\"text-align: center\">Universidad de Sevilla</p>\n",
    "<p style=\"text-align: center\">Procesamiento del Lenguaje Natural </p>\n",
    "<p style=\"text-align: center\"> Tarea 3 </p>\n",
    "<p> </p>\n",
    "\n",
    "**Nombre del alumno:**\n",
    "- Kenny Jesús Flores Huamán\n",
    "\n",
    "<!-- \n",
    "Para generar la tabla de contenidos que se va a haber a continuación, se ha hecho uso del siguiente código\n",
    "URL : https://stackoverflow.com/questions/21151450/how-can-i-add-a-table-of-contents-to-a-jupyter-jupyterlab-notebook#:~:text=Click%20the%20toc2%20symbol%20in,you%20open%20it%20in%20JupyterLab.\n",
    "\n",
    "import json\n",
    "import urllib\n",
    "def generate_toc(notebook_path, indent_char=\"&emsp;\"):\n",
    "    is_markdown = lambda it: \"markdown\" == it[\"cell_type\"]\n",
    "    is_title = lambda it: it.strip().startswith(\"#\") and it.strip().lstrip(\"#\").lstrip()\n",
    "    with open(notebook_path, 'r') as in_f:\n",
    "        nb_json = json.load(in_f)\n",
    "    for cell in filter(is_markdown, nb_json[\"cells\"]):\n",
    "        for line in filter(is_title, cell[\"source\"]):\n",
    "            line = line.strip()\n",
    "            indent = indent_char * (line.index(\" \") - 1)\n",
    "            title = line.lstrip(\"#\").lstrip()\n",
    "            url = urllib.parse.quote(title.replace(\" \", \"-\"))\n",
    "            out_line = f\"{indent}[{title}](#{url})<br>\\n\"\n",
    "            print(out_line, end=\"\")\n",
    "            \n",
    "generate_toc('C6_FloresHuaman.ipynb') -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52a1bd9",
   "metadata": {},
   "source": [
    "# Introduccion \n",
    "\n",
    "En esta tarea vamos a hacer uso de la herramienta jupyter notebook para profundizar algunos aspectos del procesamiento del lenguaje natural, en este caso vamos a realizar una predicción de la siguiente palabra que escribamos.\n",
    "\n",
    "\n",
    "# Librerias importadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cc5e698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9187daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos las stopwords en español\n",
    "stopwords = set(stopwords.words('spanish'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd80cc29",
   "metadata": {},
   "source": [
    "## Dataset utilizado\n",
    "\n",
    "En esta ocasión, debido a los nulos datasets relacionados con los chats en español, se ha decidido elegir un dataset donde recopilan [+9000 letras de rap en español](https://www.kaggle.com/datasets/smunoz3801/9325-letras-de-rap-en-espaol).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cd5e5002",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4787f1",
   "metadata": {},
   "source": [
    "Debido a que de todo el dataset lo único que nos interesa es el corpus, vamos a convertirlo en un array numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fef8e714",
   "metadata": {},
   "outputs": [],
   "source": [
    "letras = dataset['letra'].values.astype('U')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2979e84",
   "metadata": {},
   "source": [
    "Generamos una máscara para poder eliminar las letras que no tienen letra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589fd674",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.char.find(letras, '¿Tienes ya la letra para este tema? Ayúdanos y ¡Envíanosla!') == -1\n",
    "letras = letras[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef1e3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed25c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3ae2d3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "letras_limpio = []\n",
    "# Eliminamos canciones sin letra\n",
    "for letra in list(letras):\n",
    "    if \"¿Tienes ya la letra para este tema? Ayúdanos y ¡Envíanosla!\" in letra:\n",
    "        letras.remove(letra)\n",
    "\n",
    "#Eliminamos líneas vacías o con [Artista] o [Estribillo]\n",
    "for i in range(len(letras)):\n",
    "    cancion_limpia = []\n",
    "    for linea in letras[i].split(\"\\n\"):\n",
    "        if (\"[\" not in linea and \"(\" not in linea and linea != \"\"):\n",
    "            #Pasamos línea a minúsculas y eliminamos puntuación\n",
    "            linea = bytes(linea, 'utf-8').decode('utf-8', 'ignore')\n",
    "            linea = \"\".join(c for c in linea if (c not in string.punctuation and c not in ['','¡','¿'])).lower()\n",
    "            linea = linea.split(\" \")\n",
    "            #Eliminamos stopwords\n",
    "            for palabra in list(linea):\n",
    "                #palabra = palabra.replace(u'\\xa0', u'') #Estp les pasa por usar latin en vez de UTF-8\n",
    "                if palabra in stopwords or palabra in string.punctuation:\n",
    "                    linea.remove(palabra)\n",
    "            cancion_limpia += linea\n",
    "    letras_limpio += [cancion_limpia]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
